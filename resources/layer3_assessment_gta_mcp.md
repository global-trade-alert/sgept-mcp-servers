# Layer 3 Assessment: GTA MCP Server
## Prompts for Guided Workflows - Analysis & Recommendations

**Assessment Date:** 2025-11-09
**Assessed By:** Claude Code
**MCP Server:** GTA MCP (`gta-mcp`)
**Version:** Current implementation
**Reference Framework:** [MCP Best Practices - Layer 3](./mcp_best_practices.md)

---

## Executive Summary

### Overall Layer 3 Maturity: â­ (Absent)

The GTA MCP server currently has **ZERO prompts** (`@mcp.prompt()`) implemented. It is exclusively a Layer 1 (Tools) + Layer 2 (Resources) implementation with no guided workflow templates.

**Current State:**
- **0 prompts** in codebase
- **4 tools** requiring manual multi-step orchestration
- **16 resources** with excellent documentation
- **15+ documented workflows** that users perform manually

**Opportunity Assessment:**
- **High-value gap:** Documentation reveals sophisticated workflows requiring 3-5 tool calls each
- **User pain points:** Complex parameter decisions, date field confusion, query strategy cascade
- **Quick wins:** Top 5 prompts would cover 80% of common use cases
- **Implementation effort:** Low (excellent documentation serves as prompt specifications)

**Verdict:** This is the single largest opportunity to improve user experience. The absence of Layer 3 means users must manually navigate complex multi-step workflows that could be automated with prompt templates.

---

## Current Implementation Analysis

### Prompt Inventory: **ZERO**

**Files checked:**
- `src/gta_mcp/server.py` - Main server file âŒ No `@mcp.prompt()` decorators
- `src/gta_mcp/*.py` - All Python modules âŒ No prompts found
- MCP protocol exposure - âŒ No prompts listed

**What exists instead:**

| Layer | Component Count | Status |
|-------|----------------|--------|
| Layer 1: Tools | 4 tools | âœ… Excellent |
| Layer 2: Resources | 16 resources | âœ… Excellent |
| Layer 3: Prompts | 0 prompts | âŒ Absent |

**Tool inventory (manual workflow required):**
1. `gta_search_interventions` - Complex search with 15+ parameters
2. `gta_get_intervention` - Single intervention details
3. `gta_list_ticker_updates` - Change monitoring
4. `gta_get_impact_chains` - Bilateral impact analysis

Users must orchestrate these tools manually for all workflows.

### Why This Matters

**Without prompts, users must:**
1. âŒ Understand 15+ search parameters and their relationships
2. âŒ Choose correct date fields (4 options, easy to confuse)
3. âŒ Apply 3-step query strategy manually
4. âŒ Decide between MAST chapters vs intervention types
5. âŒ Understand CPC vs HS classification systems
6. âŒ Chain 3-5 tool calls for common analysis workflows
7. âŒ Remember sorting defaults and override manually
8. âŒ Navigate exclusion filter logic (11 keep_* parameters)

**With prompts, users could:**
1. âœ… Select workflow template matching their goal
2. âœ… Provide high-level parameters (country, sector, time period)
3. âœ… Let prompt handle parameter selection and tool orchestration
4. âœ… Receive structured results automatically
5. âœ… Learn by example (prompts embed best practices)

---

## User Workflow Analysis

### Documented Workflows Requiring Manual Execution

The documentation (`USAGE_EXAMPLES.md`, guides, query examples) reveals **15+ distinct workflow patterns** that users currently perform manually:

#### Category 1: Rapid Response Analysis (5 workflows)

##### 1.1 Recent Policy Changes by Country
**Current manual workflow:**
```
Step 1: Construct search parameters
  - implementing_jurisdictions=['USA']
  - date_announced_gte='2024-10-01'  # User calculates date
  - sorting='-date_announced'  # User must remember to override default

Step 2: Call gta_search_interventions

Step 3: Review results, identify top 3

Step 4: For each interesting intervention:
  - Call gta_get_intervention(intervention_id=X)
  - Extract details manually

Step 5: Synthesize findings

Complexity: 4-6 tool calls, date calculations, parameter decisions
```

**Example from documentation:**
> "Track China's rare earth export controls announced in the last 12 months"

User must:
- Calculate date (12 months ago)
- Know to use `date_announced_gte` (not `date_implemented`)
- Choose intervention types for export controls
- Remember to sort by date descending
- Chain search â†’ get_intervention calls

##### 1.2 Section 232 Tariff Timeline Analysis
**Current manual workflow:**
```
Step 1: Search all US import tariffs
  - implementing_jurisdictions=['USA']
  - intervention_types=['Import tariff']

Step 2: Manually filter results for "Section 232" mentions
  - No text search on results, must check each

Step 3: For each Section 232 tariff:
  - Call gta_get_intervention
  - Extract announcement date and product details

Step 4: Create timeline table manually

Complexity: 10+ tool calls, manual filtering, data extraction
```

**From documentation:**
> "Determine how many Section 232 tariffs the US has in the GTA database"

##### 1.3 Company-Specific Policy Tracking
**Current manual workflow:**
```
Step 1: Apply 3-step query strategy
  - Use structured filters FIRST
  - Add query='Tesla' ONLY for entity name
  - Common mistake: Put 'Tesla' in wrong parameter

Step 2: Search with correct strategy
  - query='Tesla'
  - mast_chapters=['L']  # For subsidies
  - date_announced_gte='2020-01-01'

Step 3: Get full details for top results

Step 4: Extract affected products/jurisdictions

Complexity: Strategy knowledge required, 3-5 tool calls
```

##### 1.4 Bilateral Trade Barrier Analysis
**Current manual workflow:**
```
Step 1: Search Country A â†’ Country B barriers
  - implementing_jurisdictions=['USA']
  - affected_jurisdictions=['CHN']
  - intervention_types=[list of barrier types]

Step 2: Search Country B â†’ Country A barriers
  - Swap jurisdictions
  - Repeat search

Step 3: For significant barriers:
  - Call gta_get_impact_chains
  - Identify affected products

Step 4: Compare and synthesize

Complexity: 2 searches + multiple impact chain calls + comparison logic
```

##### 1.5 Technology Export Control Tracking
**Current manual workflow:**
```
Step 1: Define export control intervention types
  - intervention_types=['Export ban', 'Export licensing requirement', 'Export quota']

Step 2: Add technology query terms
  - query='artificial intelligence | AI | machine learning'
  - Must understand query syntax (OR logic with |)

Step 3: Filter by implementing countries
  - implementing_jurisdictions=['USA', 'CHN', 'EU']

Step 4: Get impact chains for each

Complexity: Query syntax knowledge, 5+ tool calls
```

#### Category 2: Comparative Analysis (3 workflows)

##### 2.1 Cross-Country Policy Comparison
**Current manual workflow:**
```
Step 1: For each country in comparison set:
  - Run identical search with different implementing_jurisdictions
  - Store results separately

Step 2: Aggregate statistics manually:
  - Total interventions per country
  - Most common types per country
  - Affected sectors per country

Step 3: Create comparison table

Step 4: Deep dive on outliers:
  - Call gta_get_intervention for unusual measures

Complexity: N searches (one per country) + aggregation + synthesis
```

**From documentation:**
> "Compare subsidy measures across USA, China, and EU for electric vehicles"

##### 2.2 Sector-Wide Policy Landscape
**Current manual workflow:**
```
Step 1: Identify relevant CPC codes
  - Load gta://reference/sectors-list
  - Find sector codes manually
  - Decide if CPC or HS codes needed

Step 2: Search with sector filters
  - affected_sectors=['XXXXX'] for CPC
  - OR affected_products=['YYYYYY'] for HS

Step 3: Group results by:
  - Implementing country
  - Intervention type
  - Time period

Step 4: Identify trends manually

Complexity: Classification system knowledge, grouping logic, trend analysis
```

##### 2.3 Time-Series Policy Evolution
**Current manual workflow:**
```
Step 1: Define time buckets
  - E.g., 2020, 2021, 2022, 2023, 2024

Step 2: For each time bucket:
  - Search with date_announced_gte and date_announced_lte
  - Store results

Step 3: Calculate trends:
  - Count interventions per period
  - Identify policy shifts
  - Track type evolution

Step 4: Visualize timeline

Complexity: Multiple searches, trend calculation, synthesis
```

#### Category 3: Monitoring & Briefing (2 workflows)

##### 3.1 Morning Briefing Generation
**Current manual workflow:**
```
Step 1: Search yesterday's announcements
  - Calculate yesterday's date
  - implementing_jurisdictions=['USA', 'CHN', 'EU']  # Watched countries
  - date_announced_gte='2024-11-08'
  - date_announced_lte='2024-11-08'

Step 2: Check ticker updates for tracked interventions
  - gta_list_ticker_updates with intervention IDs
  - Manual tracking of which IDs to monitor

Step 3: Filter for priority items:
  - gta_evaluation='Red' (most trade-restrictive)
  - OR specific sectors of interest

Step 4: Format as briefing

Complexity: 3+ tool calls, date calculations, priority filtering
```

**From documentation:**
> "Daily monitoring of watched countries and specific intervention IDs"

##### 3.2 Tracked Policy Change Alerts
**Current manual workflow:**
```
Step 1: Maintain list of intervention IDs to monitor

Step 2: Call gta_list_ticker_updates periodically

Step 3: Filter updates for tracked IDs

Step 4: For each update:
  - Call gta_get_intervention to see new status
  - Compare with previous state

Complexity: Manual ID tracking, periodic execution, change detection
```

#### Category 4: Stakeholder Reporting (3 workflows)

##### 4.1 "How many?" Questions
**Current manual workflow:**
```
Example: "How many export controls has China implemented this year?"

Step 1: Construct precise search
  - implementing_jurisdictions=['CHN']
  - intervention_types=['Export ban', 'Export licensing requirement', 'Export quota']
  - date_announced_gte='2024-01-01'

Step 2: Count results
  - Use total_count from response

Step 3: Break down by month
  - Manual parsing of date_announced fields
  - Group and count

Step 4: Get top 3 examples
  - Call gta_get_intervention for details

Step 5: Extract sources for citation

Complexity: Counting logic, date parsing, detail extraction
```

##### 4.2 "What's the impact?" Analysis
**Current manual workflow:**
```
Example: "What's the impact of US tariffs on Chinese steel?"

Step 1: Find relevant tariffs
  - implementing_jurisdictions=['USA']
  - affected_jurisdictions=['CHN']
  - intervention_types=['Import tariff']
  - query='steel'

Step 2: For each tariff:
  - Call gta_get_impact_chains
  - Extract upstream/downstream effects

Step 3: Aggregate product codes
  - Identify all affected HS codes
  - Group by steel category

Step 4: Synthesize impact narrative

Complexity: Search + impact chains (multiple) + aggregation + synthesis
```

##### 4.3 Source Documentation Extraction
**Current manual workflow:**
```
Step 1: Find interventions of interest

Step 2: For each:
  - Call gta_get_intervention
  - Extract official_source_title
  - Extract official_source_link
  - Extract implementing_jurisdiction details

Step 3: Format citations manually

Complexity: Multiple detail calls, manual citation formatting
```

#### Category 5: Advanced Research (2 workflows)

##### 5.1 Service Sector Restrictions
**Current manual workflow:**
```
Step 1: Recognize this is services (not goods)
  - MUST use CPC sectors (ID >= 500)
  - Cannot use HS codes (they don't cover services)

Step 2: Identify CPC codes
  - Load gta://reference/sectors-list
  - Find service sectors manually
  - E.g., 71 = Financial services, 72 = Legal services

Step 3: Search with affected_sectors
  - NOT affected_products (HS codes)

Step 4: Analyze cross-border implications

Complexity: Classification system expertise required
```

**Common mistake:** Using affected_products for services â†’ zero results

##### 5.2 Subsidy Deep Dive
**Current manual workflow:**
```
Step 1: Decide on scope
  - Broad: mast_chapters=['L']  # All subsidies
  - Specific: intervention_types=['State aid', 'Financial grant', ...]

Step 2: Common mistake check
  - Don't use BOTH mast_chapters=['L'] AND specific subsidy types
  - This is redundant (L includes all subsidy types)

Step 3: Search with correct filter

Step 4: Break down by subsidy instrument
  - Group results by intervention_type
  - Count each type

Complexity: MAST taxonomy knowledge, anti-pattern avoidance
```

---

## Coverage Gap Analysis

### What % of Common Use Cases Have Prompt Templates?

**0% coverage** (0 prompts / 15+ documented workflows)

### Workflow Complexity Assessment

| Workflow | Tool Calls Required | Parameter Decisions | Knowledge Prerequisites | Prompt Value |
|----------|-------------------|-------------------|------------------------|--------------|
| Recent policy analysis | 2-4 | Date field, sorting | Date semantics | ðŸ”´ Very High |
| Bilateral trade tensions | 3-5 | Dual jurisdictions, impact chains | Tool orchestration | ðŸ”´ Very High |
| Morning briefing | 3-4 | Date calculation, filtering | Monitoring patterns | ðŸ”´ Very High |
| Company tracking | 2-3 | Query strategy | 3-step cascade | ðŸŸ¡ High |
| Sector barriers | 2-4 | CPC vs HS, grouping | Classification systems | ðŸ”´ Very High |
| Cross-country comparison | 3N (N countries) | Aggregation | Multi-query synthesis | ðŸŸ¡ High |
| Subsidy landscape | 2-3 | MAST chapters | Taxonomy | ðŸŸ¡ High |
| Service sector analysis | 2-3 | CPC sectors | Service classification | ðŸ”´ Very High |
| Export control tracking | 2-4 | Query syntax, types | OR logic | ðŸŸ¡ High |
| Active policies dashboard | 1-2 | is_in_force flag | Date fields | ðŸŸ¡ High |
| Section 232 timeline | 5-10 | Manual filtering | Text search | ðŸŸ¡ High |
| Time-series analysis | 2N (N periods) | Date buckets | Trend calculation | ðŸŸ¡ High |
| Impact analysis | 3-5 | Impact chains | Product codes | ðŸŸ¡ High |
| Source extraction | N+1 (N interventions) | Citation formatting | Detail extraction | ðŸŸ¢ Medium |
| Tracked changes | 2-3 | ID tracking | Change detection | ðŸŸ¢ Medium |

**Key Metrics:**
- **Average tool calls per workflow:** 3.2
- **Average parameter decisions:** 4.5
- **Workflows requiring expert knowledge:** 10/15 (67%)
- **High-value prompt opportunities:** 9/15 (60%)

---

## High-Impact Prompt Recommendations

### Tier 1: Critical Workflows (Implement First)

These 5 prompts cover the most common use cases and highest pain points.

#### Prompt 1: Recent Policy Analysis ðŸ”´ Critical

**Prompt Name:** `recent-policy-analysis`

**Purpose:** Analyze recent trade policy changes from a specific country, handling date calculations and sorting automatically.

**User Pain Points Addressed:**
- âŒ Manual date calculations ("last 30 days" â†’ convert to date)
- âŒ Date field confusion (date_announced vs date_implemented vs date_removed)
- âŒ Sorting defaults (API defaults to oldest-first, users want newest-first)
- âŒ Multi-step workflow (search â†’ identify top items â†’ get details)

**Parameters:**
```python
@mcp.prompt()
async def recent_policy_analysis(
    country: str,                    # Required: ISO 3-letter code (e.g., 'USA', 'CHN')
    policy_type: Optional[str] = None,  # Optional: Intervention type filter
    days_back: int = 30,             # How many days to look back (default: 30)
    evaluation: Optional[str] = None    # Optional: 'Red', 'Amber', 'Green'
) -> list[PromptMessage]:
```

**Workflow Automation:**
```
Manual (current):                      With Prompt:
1. Calculate date (today - 30 days)   â†’ Automatic
2. Choose date field                  â†’ Uses date_announced (correct default)
3. Set sorting                        â†’ Applies -date_announced automatically
4. Call gta_search_interventions      â†’ Embedded in prompt
5. Review top results                 â†’ Automatic
6. Get details for top 3              â†’ Automatic (optional)
7. Synthesize                         â†’ LLM guided by prompt structure

5-7 steps â†’ 1 prompt invocation
```

**Implementation:**
```python
@mcp.prompt()
async def recent_policy_analysis(
    country: str,
    policy_type: Optional[str] = None,
    days_back: int = 30,
    evaluation: Optional[str] = None
) -> list[PromptMessage]:
    """Analyze recent trade policy changes from a specific country.

    Automatically handles:
    - Date calculations (days_back â†’ date_announced_gte)
    - Correct date field selection (uses date_announced)
    - Proper sorting (newest first)
    - Top results highlighting

    Args:
        country: ISO 3-letter country code (e.g., 'USA', 'CHN', 'DEU')
        policy_type: Optional intervention type filter (e.g., 'Import tariff')
        days_back: Number of days to look back (default: 30)
        evaluation: Optional GTA evaluation filter ('Red', 'Amber', 'Green')

    Returns:
        Prompt messages with embedded search results and analysis guidance
    """
    from datetime import datetime, timedelta

    # Calculate cutoff date
    cutoff_date = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")

    # Build search parameters
    params = {
        "implementing_jurisdictions": [country.upper()],
        "date_announced_gte": cutoff_date,
        "sorting": "-date_announced",  # Newest first
        "limit": 20
    }

    if policy_type:
        params["intervention_types"] = [policy_type]

    if evaluation:
        params["gta_evaluation"] = evaluation

    # Execute search
    results = await execute_search(params)

    # Format results for embedding
    formatted_results = format_interventions_table(results)

    # Build prompt message
    prompt_text = f"""# Recent Trade Policy Analysis: {country}

## Context
Analyzing trade policy interventions announced by **{country}** in the **last {days_back} days** (since {cutoff_date}).
"""

    if policy_type:
        prompt_text += f"- **Filtered by:** {policy_type}\n"

    if evaluation:
        prompt_text += f"- **Evaluation filter:** {evaluation} (trade restrictiveness)\n"

    prompt_text += f"""
## Search Results

Found **{results.get('total_count', 0)} interventions** matching criteria:

{formatted_results}

## Analysis Tasks

Please analyze these recent policy changes and provide:

### 1. Executive Summary
- What is the overall policy direction? (more protectionist, liberalizing, sector-specific, etc.)
- Are there clear patterns or themes?

### 2. Most Significant Measures
Identify the 3 most significant interventions based on:
- Breadth of impact (products/sectors affected)
- Trade restrictiveness (GTA evaluation)
- Strategic importance

For each, explain:
- What does this measure do?
- Who/what is affected?
- Why is this significant?

### 3. Sectoral Analysis
- Which sectors are most affected?
- Are there sector-specific trends?

### 4. Trading Partner Implications
- Which countries are most affected by these measures?
- Any bilateral patterns (targeting specific countries)?

### 5. Temporal Patterns
- Is there clustering of announcements (e.g., multiple measures on same day)?
- Any correlation with external events?

## Additional Context

If you need more information:
- For full details on any intervention: Use `gta_get_intervention(intervention_id=X)`
- For supply chain impacts: Use `gta_get_impact_chains(intervention_id=X)`
- For intervention type definitions: See `gta://reference/intervention-types`
- For country codes: See `gta://reference/jurisdictions`
"""

    return [
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": prompt_text
            }
        },
        {
            "role": "user",
            "content": {
                "type": "resource",
                "resource": {
                    "uri": "gta://guide/query-examples",
                    "mimeType": "text/markdown",
                    "text": "Load query examples for reference"
                }
            }
        }
    ]
```

**Example Usage:**
```
User: "Use prompt: recent-policy-analysis country='CHN' policy_type='Export ban' days_back=90"

Result: Automatic analysis of China's export bans from last 90 days, with:
- Embedded search results
- Analysis framework
- Guidance on next steps
```

**Impact Metrics:**
- **User steps reduced:** 7 â†’ 1 (86% reduction)
- **Parameter decisions eliminated:** 4 (date, field, sorting, limit)
- **Common errors prevented:** Date field confusion, wrong sorting, date calculation
- **Use case coverage:** Rapid response, morning briefing, daily monitoring

---

#### Prompt 2: Bilateral Trade Tensions ðŸ”´ Critical

**Prompt Name:** `bilateral-trade-tensions`

**Purpose:** Analyze trade measures between two countries, automatically running dual searches and impact chain analysis.

**User Pain Points Addressed:**
- âŒ Must run 2 separate searches (Aâ†’B and Bâ†’A)
- âŒ Must manually compare and synthesize results
- âŒ Impact chain calls for significant measures
- âŒ Timeline alignment for retaliatory patterns

**Parameters:**
```python
@mcp.prompt()
async def bilateral_trade_tensions(
    country_a: str,                  # Required: First country ISO code
    country_b: str,                  # Required: Second country ISO code
    evaluation: Optional[str] = None,   # Optional: Filter by trade restrictiveness
    period_start: str = "2018-01-01",   # Default: Start of recent trade tensions
    include_impact_chains: bool = True  # Whether to analyze supply chain effects
) -> list[PromptMessage]:
```

**Workflow Automation:**
```
Manual (current):                      With Prompt:
1. Search A â†’ B                       â†’ Automatic (parallel execution)
2. Search B â†’ A                       â†’ Automatic (parallel execution)
3. Get impact chains for top items    â†’ Automatic (if include_impact_chains=True)
4. Align timelines                    â†’ Automatic (sorted by date)
5. Identify retaliation patterns      â†’ LLM guided by prompt
6. Compare affected products          â†’ Automatic (product extraction)
7. Synthesize narrative               â†’ LLM guided by prompt

7 steps â†’ 1 prompt invocation
```

**Implementation:**
```python
@mcp.prompt()
async def bilateral_trade_tensions(
    country_a: str,
    country_b: str,
    evaluation: Optional[str] = None,
    period_start: str = "2018-01-01",
    include_impact_chains: bool = True
) -> list[PromptMessage]:
    """Analyze bilateral trade tensions between two countries.

    Automatically:
    - Searches measures in both directions (Aâ†’B and Bâ†’A)
    - Aligns timelines for retaliation analysis
    - Gets impact chains for significant measures
    - Compares affected products/sectors

    Args:
        country_a: First country ISO code
        country_b: Second country ISO code
        evaluation: Optional filter ('Red', 'Amber', 'Green')
        period_start: Analysis start date (default: 2018-01-01)
        include_impact_chains: Whether to analyze supply chains (default: True)

    Returns:
        Prompt with embedded bilateral analysis data
    """

    # Search A â†’ B measures
    params_a_to_b = {
        "implementing_jurisdictions": [country_a.upper()],
        "affected_jurisdictions": [country_b.upper()],
        "date_announced_gte": period_start,
        "sorting": "date_announced",  # Chronological for timeline
        "limit": 100
    }

    if evaluation:
        params_a_to_b["gta_evaluation"] = evaluation

    # Search B â†’ A measures (parallel execution possible)
    params_b_to_a = {
        "implementing_jurisdictions": [country_b.upper()],
        "affected_jurisdictions": [country_a.upper()],
        "date_announced_gte": period_start,
        "sorting": "date_announced",
        "limit": 100
    }

    if evaluation:
        params_b_to_a["gta_evaluation"] = evaluation

    # Execute searches (can be parallel in real implementation)
    results_a_to_b = await execute_search(params_a_to_b)
    results_b_to_a = await execute_search(params_b_to_a)

    # Get impact chains for top 5 measures from each direction (if enabled)
    impact_data = None
    if include_impact_chains:
        top_a_to_b = results_a_to_b.get("results", [])[:5]
        top_b_to_a = results_b_to_a.get("results", [])[:5]

        impact_data = {
            "a_to_b": [await get_impact_chains(i["intervention_id"]) for i in top_a_to_b],
            "b_to_a": [await get_impact_chains(i["intervention_id"]) for i in top_b_to_a]
        }

    # Format results
    formatted_a_to_b = format_interventions_timeline(results_a_to_b, country_a, country_b)
    formatted_b_to_a = format_interventions_timeline(results_b_to_a, country_b, country_a)

    # Build prompt
    prompt_text = f"""# Bilateral Trade Tensions Analysis: {country_a} â†” {country_b}

## Overview
Analyzing trade measures between **{country_a}** and **{country_b}** since {period_start}.

## Measures Summary

### {country_a} â†’ {country_b}
**{results_a_to_b.get('total_count', 0)} interventions** implemented by {country_a} affecting {country_b}:

{formatted_a_to_b}

---

### {country_b} â†’ {country_a}
**{results_b_to_a.get('total_count', 0)} interventions** implemented by {country_b} affecting {country_a}:

{formatted_b_to_a}

---
"""

    if impact_data:
        prompt_text += f"""
## Supply Chain Impact Analysis

Impact chains for top measures have been analyzed. Key affected products and sectors are embedded in the data above.
"""

    prompt_text += f"""
## Analysis Tasks

### 1. Timeline Analysis
- **Who initiated?** Which country implemented the first measure?
- **Retaliatory patterns?** Are there matching announcement dates suggesting retaliation?
- **Escalation vs de-escalation?** Is the situation intensifying or cooling?
- **Key inflection points?** Identify dates with major policy shifts

### 2. Product/Sector Analysis
- **Most targeted products:** Which HS codes appear most frequently?
- **Strategic sectors:** Which sectors are primary targets (tech, agriculture, manufacturing)?
- **Asymmetries:** Are both countries targeting similar sectors, or different strategies?

### 3. Measure Characteristics
- **Policy instruments:** What types of measures are used (tariffs, quotas, bans, subsidies)?
- **Trade restrictiveness:** Compare GTA evaluations (Red vs Amber vs Green)
- **Breadth vs precision:** Broad sectoral measures or targeted product lists?

### 4. Current Status
- **Active measures:** How many are currently in force?
- **Removed measures:** Any signs of de-escalation?
- **Recent developments:** What happened in the last 90 days?

### 5. Implications
- **Trade flow impact:** Which bilateral trade flows are most disrupted?
- **Third-party effects:** Are other countries affected via supply chains?
- **Outlook:** Based on patterns, is this likely to escalate or stabilize?

## Next Steps

For deeper analysis:
- **Full measure details:** Use `gta_get_intervention(intervention_id=X)` for any specific measure
- **Extended impact chains:** Use `gta_get_impact_chains(intervention_id=X, direction='both')`
- **Recent updates:** Use `gta_list_ticker_updates` for latest changes
"""

    return [
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": prompt_text
            }
        },
        {
            "role": "user",
            "content": {
                "type": "resource",
                "resource": {
                    "uri": "gta://guide/date-fields",
                    "mimeType": "text/markdown",
                    "text": "Date field reference for understanding timelines"
                }
            }
        }
    ]
```

**Example Usage:**
```
User: "Use prompt: bilateral-trade-tensions country_a='USA' country_b='CHN' evaluation='Red'"

Result: Complete bilateral analysis with:
- Both directional searches
- Timeline alignment
- Product comparisons
- Impact chain data
- Guided analysis framework
```

**Impact Metrics:**
- **User steps reduced:** 7 â†’ 1 (86% reduction)
- **Searches automated:** 2 (parallel execution)
- **Impact chain calls:** 5-10 (automatic for top measures)
- **Common errors prevented:** Forgetting reverse search, timeline misalignment

---

#### Prompt 3: Morning Briefing Generator ðŸ”´ Critical

**Prompt Name:** `morning-briefing`

**Purpose:** Generate daily briefing of new interventions and updates from watched countries/interventions.

**User Pain Points Addressed:**
- âŒ Daily date calculations ("yesterday" â†’ exact date)
- âŒ Multiple tool calls (new interventions + ticker updates + filtering)
- âŒ Manual tracking of intervention IDs to monitor
- âŒ Priority filtering and synthesis

**Parameters:**
```python
@mcp.prompt()
async def morning_briefing(
    watched_countries: List[str] = ["USA", "CHN", "EU"],  # Countries to monitor
    watched_intervention_ids: Optional[List[int]] = None,  # Specific interventions to track
    days_back: int = 1,                                    # How many days to include
    priority_only: bool = True,                            # Only Red-evaluated or critical sectors
    critical_sectors: Optional[List[str]] = None           # Sector keywords for highlighting
) -> list[PromptMessage]:
```

**Workflow Automation:**
```
Manual (current):                      With Prompt:
1. Calculate yesterday's date         â†’ Automatic
2. Search new interventions           â†’ Automatic (parallel by country)
3. Check ticker updates               â†’ Automatic (if IDs provided)
4. Filter for priority items          â†’ Automatic (Red evaluation + sectors)
5. Format as briefing                 â†’ Automatic (structured output)
6. Highlight key items                â†’ LLM guided by priority flags

6 steps + 3 tool calls â†’ 1 prompt invocation
```

**Implementation:**
```python
@mcp.prompt()
async def morning_briefing(
    watched_countries: List[str] = ["USA", "CHN", "EU"],
    watched_intervention_ids: Optional[List[int]] = None,
    days_back: int = 1,
    priority_only: bool = True,
    critical_sectors: Optional[List[str]] = None
) -> list[PromptMessage]:
    """Generate morning briefing of trade policy developments.

    Automatically:
    - Calculates date range (last N days)
    - Searches new interventions from watched countries
    - Checks updates for tracked intervention IDs
    - Filters for priority items (Red evaluation)
    - Formats as structured briefing

    Args:
        watched_countries: List of country ISO codes to monitor
        watched_intervention_ids: Optional list of intervention IDs to track for updates
        days_back: Number of days to include (default: 1 for yesterday)
        priority_only: Only include Red-evaluated or critical sector items
        critical_sectors: Keywords for sector highlighting (e.g., ['semiconductors', 'AI'])

    Returns:
        Structured morning briefing prompt
    """
    from datetime import datetime, timedelta

    # Calculate date range
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days_back)

    date_gte = start_date.strftime("%Y-%m-%d")
    date_lte = end_date.strftime("%Y-%m-%d")

    # Search new interventions for each watched country
    new_interventions = {}
    for country in watched_countries:
        params = {
            "implementing_jurisdictions": [country.upper()],
            "date_announced_gte": date_gte,
            "date_announced_lte": date_lte,
            "sorting": "-date_announced",
            "limit": 50
        }

        if priority_only:
            params["gta_evaluation"] = "Red"

        results = await execute_search(params)
        new_interventions[country] = results

    # Check ticker updates for tracked interventions
    ticker_updates = None
    if watched_intervention_ids:
        ticker_updates = await list_ticker_updates(
            intervention_ids=watched_intervention_ids,
            limit=50
        )

    # Filter for critical sectors if specified
    sector_highlights = []
    if critical_sectors:
        for country, results in new_interventions.items():
            for intervention in results.get("results", []):
                # Check if any critical sector keyword appears in intervention
                if any(sector.lower() in intervention.get("title", "").lower()
                       for sector in critical_sectors):
                    sector_highlights.append({
                        "country": country,
                        "intervention": intervention
                    })

    # Build briefing
    briefing_date = end_date.strftime("%Y-%m-%d")

    prompt_text = f"""# Trade Policy Morning Briefing
**Date:** {briefing_date}
**Coverage:** Last {days_back} day(s)
**Watched Countries:** {', '.join(watched_countries)}

---

## ðŸš¨ Priority Alerts
"""

    # Add sector highlights
    if sector_highlights:
        prompt_text += "\n### Critical Sector Developments\n\n"
        for item in sector_highlights:
            intervention = item["intervention"]
            prompt_text += f"""**{item['country']}** - {intervention.get('title', 'Untitled')}
- **ID:** {intervention.get('intervention_id')}
- **Announced:** {intervention.get('date_announced')}
- **Type:** {intervention.get('intervention_type')}
- **Evaluation:** {intervention.get('gta_evaluation', 'N/A')}

"""
    else:
        prompt_text += "\n*No critical sector developments in watched categories.*\n\n"

    # Add new interventions by country
    prompt_text += "\n---\n\n## ðŸ“Š New Interventions by Country\n\n"

    total_new = 0
    for country in watched_countries:
        results = new_interventions.get(country, {})
        count = results.get('total_count', 0)
        total_new += count

        prompt_text += f"### {country}\n"
        prompt_text += f"**{count} new intervention(s)**"

        if priority_only:
            prompt_text += " (Red-evaluated only)"

        prompt_text += "\n\n"

        if count > 0:
            # Format top interventions
            formatted = format_interventions_brief(results, limit=5)
            prompt_text += formatted + "\n\n"
        else:
            prompt_text += "*No new interventions in this period.*\n\n"

    # Add ticker updates
    if ticker_updates:
        prompt_text += "\n---\n\n## ðŸ“ Tracked Intervention Updates\n\n"

        updates_count = len(ticker_updates.get("results", []))
        prompt_text += f"**{updates_count} update(s)** to tracked interventions:\n\n"

        formatted_updates = format_ticker_updates(ticker_updates)
        prompt_text += formatted_updates + "\n\n"

    # Summary and action items
    prompt_text += f"""
---

## ðŸ“‹ Summary

- **Total new interventions:** {total_new}
- **Critical sector highlights:** {len(sector_highlights)}
- **Tracked updates:** {len(ticker_updates.get('results', [])) if ticker_updates else 0}

## ðŸŽ¯ Recommended Actions

Based on this briefing, please:

1. **Highlight top 3 most significant developments**
   - Consider: Trade restrictiveness, affected sectors, strategic importance

2. **Flag items requiring immediate attention**
   - Red-evaluated measures
   - Critical sector interventions
   - Major updates to tracked policies

3. **Provide brief context for each key item**
   - What does this measure do?
   - Who is affected?
   - Why does it matter?

4. **Suggest follow-up actions**
   - Which interventions need full detail review?
   - Any trends emerging that warrant deeper analysis?

## ðŸ” For More Details

- **Full intervention details:** `gta_get_intervention(intervention_id=X)`
- **Impact analysis:** `gta_get_impact_chains(intervention_id=X)`
- **Broader search:** Adjust `watched_countries` or remove `priority_only` filter
"""

    return [
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": prompt_text
            }
        }
    ]
```

**Example Usage:**
```
User: "Use prompt: morning-briefing watched_countries=['USA','CHN','EU'] critical_sectors=['semiconductors','AI']"

Result: Structured briefing with:
- Yesterday's new interventions from USA, CHN, EU
- Highlights for semiconductor/AI policies
- Updates to tracked interventions
- Action recommendations
```

**Impact Metrics:**
- **User steps reduced:** 6 â†’ 1 (83% reduction)
- **Tool calls automated:** 3-4 (search per country + ticker updates)
- **Date calculations:** Automatic (yesterday, date ranges)
- **Use case coverage:** Daily monitoring, rapid response, stakeholder alerts

---

#### Prompt 4: Sector Barriers Analysis ðŸ”´ Critical

**Prompt Name:** `sector-barriers-analysis`

**Purpose:** Analyze trade barriers affecting a specific sector, handling CPC vs HS classification automatically.

**User Pain Points Addressed:**
- âŒ CPC vs HS decision (services require CPC, goods can use either)
- âŒ Sector code lookup (which codes apply to this sector?)
- âŒ Grouping logic (by country, by barrier type, by time)
- âŒ Result synthesis across multiple dimensions

**Parameters:**
```python
@mcp.prompt()
async def sector_barriers_analysis(
    sector: str,                             # Required: Sector name or code
    implementing_countries: Optional[List[str]] = None,  # Filter by implementing country
    affected_countries: Optional[List[str]] = None,      # Filter by affected country
    barrier_types: Optional[List[str]] = None,  # Specific intervention types
    evaluation: Optional[str] = None,        # Red/Amber/Green filter
    period_start: str = "2020-01-01"         # Analysis start date
) -> list[PromptMessage]:
```

**Workflow Automation:**
```
Manual (current):                      With Prompt:
1. Identify if sector is goods/services â†’ Automatic (sector name analysis)
2. Look up CPC or HS codes            â†’ Automatic (sector mapping)
3. Choose affected_sectors vs products â†’ Automatic (based on classification)
4. Search with correct parameters     â†’ Automatic
5. Group by implementing country      â†’ Automatic (aggregation)
6. Group by intervention type         â†’ Automatic (aggregation)
7. Synthesize multi-dimensional view  â†’ LLM guided by prompt

7 steps â†’ 1 prompt invocation
```

**Implementation:**
```python
@mcp.prompt()
async def sector_barriers_analysis(
    sector: str,
    implementing_countries: Optional[List[str]] = None,
    affected_countries: Optional[List[str]] = None,
    barrier_types: Optional[List[str]] = None,
    evaluation: Optional[str] = None,
    period_start: str = "2020-01-01"
) -> list[PromptMessage]:
    """Analyze trade barriers affecting a specific sector.

    Automatically:
    - Determines if sector is goods (HS) or services (CPC)
    - Maps sector name to relevant codes
    - Chooses correct parameter (affected_products vs affected_sectors)
    - Groups results by country and intervention type
    - Provides multi-dimensional analysis

    Args:
        sector: Sector name (e.g., 'semiconductors', 'financial services') or code
        implementing_countries: Optional filter for countries imposing barriers
        affected_countries: Optional filter for countries affected
        barrier_types: Optional intervention type filters
        evaluation: Optional GTA evaluation filter
        period_start: Analysis start date

    Returns:
        Multi-dimensional sector barrier analysis
    """

    # Determine if sector is goods or services and map to codes
    sector_info = await resolve_sector_to_codes(sector)
    # Returns: {"type": "goods"|"services", "codes": [...], "classification": "HS"|"CPC"}

    # Build search parameters based on classification
    params = {
        "date_announced_gte": period_start,
        "sorting": "-date_announced",
        "limit": 200
    }

    # Use correct parameter based on classification
    if sector_info["classification"] == "HS":
        params["affected_products"] = sector_info["codes"]
    else:  # CPC for services
        params["affected_sectors"] = sector_info["codes"]

    if implementing_countries:
        params["implementing_jurisdictions"] = [c.upper() for c in implementing_countries]

    if affected_countries:
        params["affected_jurisdictions"] = [c.upper() for c in affected_countries]

    if barrier_types:
        params["intervention_types"] = barrier_types

    if evaluation:
        params["gta_evaluation"] = evaluation

    # Execute search
    results = await execute_search(params)

    # Aggregate results
    aggregations = aggregate_sector_results(results, group_by=["implementing_jurisdiction", "intervention_type", "date"])

    # Format results
    prompt_text = f"""# Sector Barriers Analysis: {sector.title()}

## Sector Classification
- **Sector:** {sector}
- **Classification:** {sector_info["classification"]} codes
- **Codes analyzed:** {', '.join(sector_info["codes"][:10])}{'...' if len(sector_info["codes"]) > 10 else ''}
- **Period:** Since {period_start}

## Search Results

Found **{results.get('total_count', 0)} interventions** affecting {sector}:

### By Implementing Country

"""

    # Add country breakdown
    for country, count in aggregations["by_country"].items():
        prompt_text += f"**{country}:** {count} interventions\n"

    prompt_text += "\n### By Intervention Type\n\n"

    # Add intervention type breakdown
    for itype, count in aggregations["by_type"].items():
        prompt_text += f"**{itype}:** {count} interventions\n"

    prompt_text += f"""

### Timeline

{format_timeline_chart(aggregations["by_date"])}

---

## Detailed Results

{format_interventions_table(results, limit=50)}

---

## Analysis Tasks

### 1. Barrier Landscape
- **Most restrictive countries:** Which countries impose the most/heaviest barriers on {sector}?
- **Common barrier types:** What policy instruments are used (tariffs, quotas, bans, standards)?
- **Trade restrictiveness:** Distribution of Red/Amber/Green evaluations?

### 2. Temporal Trends
- **Evolution over time:** Is protectionism in {sector} increasing or decreasing?
- **Policy waves:** Are there clusters of measures (suggesting coordinated action)?
- **Recent developments:** What happened in the last 6 months?

### 3. Geographic Patterns
- **Most affected countries:** Which countries' {sector} exports face most barriers?
- **Regional patterns:** EU vs US vs China - different approaches?
- **Bilateral tensions:** Any specific country-pair conflicts in {sector}?

### 4. Product/Service Specificity
- **Sub-sector targeting:** Are specific {sector} products/services targeted more than others?
- **Technology components:** For tech sectors, which components face barriers?

### 5. Strategic Assessment
- **Industrial policy:** Evidence of countries protecting domestic {sector} industries?
- **Supply chain security:** Barriers driven by supply chain resilience concerns?
- **Geopolitical factors:** Correlation with broader geopolitical tensions?

## Classification Note

"""

    if sector_info["classification"] == "CPC":
        prompt_text += f"""**Note:** {sector} is classified as a service sector, so this analysis uses **CPC codes**
(not HS codes, which only cover goods). Service sector barriers often include:
- Cross-border supply restrictions
- Commercial presence requirements
- Licensing and qualification requirements
- Market access limitations
"""
    else:
        prompt_text += f"""**Note:** {sector} is classified as goods, so this analysis uses **HS codes**.
For broader sectoral analysis, you could also search using CPC sector codes.
"""

    prompt_text += """

## Next Steps

For deeper analysis:
- **Product-level detail:** Use `gta_get_intervention(intervention_id=X)` for specific measures
- **Impact chains:** Use `gta_get_impact_chains(intervention_id=X)` to see supply chain effects
- **Compare countries:** Re-run analysis with different `implementing_countries` filters
- **Classification guide:** See `gta://guide/cpc-vs-hs` for more on product classification
"""

    return [
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": prompt_text
            }
        },
        {
            "role": "user",
            "content": {
                "type": "resource",
                "resource": {
                    "uri": "gta://guide/cpc-vs-hs",
                    "mimeType": "text/markdown",
                    "text": "CPC vs HS classification guide"
                }
            }
        }
    ]
```

**Example Usage:**
```
User: "Use prompt: sector-barriers-analysis sector='financial services' implementing_countries=['USA','EU']"

Result: Complete sector analysis with:
- Automatic CPC code detection (services)
- Country and type aggregations
- Timeline visualization
- Guided analysis framework
```

**Impact Metrics:**
- **User steps reduced:** 7 â†’ 1 (86% reduction)
- **Classification decision:** Automatic (CPC vs HS)
- **Code lookup:** Automatic (sector name â†’ codes)
- **Aggregation:** Automatic (multi-dimensional grouping)
- **Common errors prevented:** Using HS codes for services, wrong parameter selection

---

#### Prompt 5: Company Impact Tracker ðŸŸ¡ High Priority

**Prompt Name:** `company-impact-tracker`

**Purpose:** Track all government policies affecting a specific company, applying the 3-step query strategy automatically.

**User Pain Points Addressed:**
- âŒ Query strategy cascade (structured filters FIRST, then query parameter)
- âŒ Common mistake: Putting company name in wrong parameter
- âŒ Policy categorization (support vs restrictive vs neutral)
- âŒ Geographic analysis (which countries supporting/restricting)

**Parameters:**
```python
@mcp.prompt()
async def company_impact_tracker(
    company_name: str,                       # Required: Company name
    policy_scope: str = "all",               # 'subsidies', 'restrictions', 'all'
    implementing_countries: Optional[List[str]] = None,  # Filter by country
    period_start: str = "2020-01-01"         # Analysis start date
) -> list[PromptMessage]:
```

**Workflow Automation:**
```
Manual (current):                      With Prompt:
1. Remember 3-step query strategy     â†’ Automatic (structured filters first)
2. Choose correct policy filters      â†’ Automatic (based on policy_scope)
3. Apply query parameter correctly    â†’ Automatic (company_name in query only)
4. Search                             â†’ Automatic
5. Categorize results                 â†’ Automatic (support/restrictive/neutral)
6. Geographic analysis                â†’ Automatic (country grouping)

6 steps â†’ 1 prompt invocation
```

**Implementation:**
```python
@mcp.prompt()
async def company_impact_tracker(
    company_name: str,
    policy_scope: str = "all",
    implementing_countries: Optional[List[str]] = None,
    period_start: str = "2020-01-01"
) -> list[PromptMessage]:
    """Track government policies affecting a specific company.

    Automatically applies the 3-step query strategy:
    1. Structured filters FIRST (policy types, countries, dates)
    2. Query parameter ONLY for company name
    3. Avoid common mistake of using wrong parameters

    Categorizes results by:
    - Support measures (subsidies, grants, tax breaks)
    - Restrictive measures (tariffs, bans, sanctions)
    - Neutral regulations (standards, reporting)

    Args:
        company_name: Company name (e.g., 'Tesla', 'Huawei', 'TSMC')
        policy_scope: 'subsidies', 'restrictions', 'all' (default: 'all')
        implementing_countries: Optional country filter
        period_start: Analysis start date

    Returns:
        Comprehensive company policy impact analysis
    """

    # Map policy_scope to filters (structured filters FIRST - step 1 of strategy)
    scope_filters = {
        "subsidies": {
            "mast_chapters": ["L"]  # All subsidies
        },
        "restrictions": {
            "intervention_types": [
                "Import tariff", "Import ban", "Export ban",
                "Export licensing requirement", "Sanction"
            ]
        },
        "all": {}  # No filter, all intervention types
    }

    # Build search parameters
    params = {
        "query": company_name,  # Step 2: Query parameter for entity name ONLY
        "date_announced_gte": period_start,
        "sorting": "-date_announced",
        "limit": 100,
        **scope_filters.get(policy_scope, {})
    }

    if implementing_countries:
        params["implementing_jurisdictions"] = [c.upper() for c in implementing_countries]

    # Execute search
    results = await execute_search(params)

    # Categorize results
    categorized = categorize_company_policies(results, company_name)
    # Returns: {"support": [...], "restrictive": [...], "neutral": [...]}

    # Geographic analysis
    geo_analysis = analyze_geographic_pattern(categorized)
    # Returns: {"supporting_countries": [...], "restricting_countries": [...]}

    # Format results
    prompt_text = f"""# Company Policy Impact Tracker: {company_name}

## Search Configuration

**Applied 3-Step Query Strategy:**
1. âœ… **Structured filters FIRST:** {scope_filters.get(policy_scope, 'All intervention types')}
2. âœ… **Query parameter for entity name:** '{company_name}'
3. âœ… **Avoided common mistakes:** Did not put company name in wrong parameters

**Search Parameters:**
- **Company:** {company_name}
- **Policy scope:** {policy_scope}
- **Period:** Since {period_start}
- **Countries:** {', '.join(implementing_countries) if implementing_countries else 'All'}

**Results:** {results.get('total_count', 0)} interventions mentioning {company_name}

---

## Policy Categorization

### ðŸŸ¢ Support Measures ({len(categorized['support'])} interventions)
Government policies supporting or benefiting {company_name}:

{format_interventions_category(categorized['support'])}

### ðŸ”´ Restrictive Measures ({len(categorized['restrictive'])} interventions)
Government policies restricting or hindering {company_name}:

{format_interventions_category(categorized['restrictive'])}

### âšª Neutral/Regulatory Measures ({len(categorized['neutral'])} interventions)
Government policies affecting {company_name} without clear support/restriction:

{format_interventions_category(categorized['neutral'])}

---

## Geographic Analysis

### Countries Supporting {company_name}
{format_country_list(geo_analysis['supporting_countries'])}

### Countries Restricting {company_name}
{format_country_list(geo_analysis['restricting_countries'])}

### Geographic Pattern Summary
{format_geographic_summary(geo_analysis)}

---

## Timeline

{format_timeline_chart(categorized, company_name)}

---

## Analysis Tasks

### 1. Overall Policy Environment
- **Net assessment:** Is the global policy environment favorable or hostile to {company_name}?
- **Trend direction:** Is policy sentiment improving or deteriorating over time?
- **Balance:** Ratio of support to restrictive measures?

### 2. Geographic Strategy Implications
- **Friendly markets:** Which countries are most supportive? Investment opportunities?
- **Hostile markets:** Which countries pose greatest barriers? Risk mitigation needed?
- **Neutral territories:** Which countries could be cultivated?

### 3. Policy Type Patterns
- **Support mechanisms:** What types of support (R&D grants, tax breaks, procurement preferences)?
- **Restriction patterns:** What barriers (tariffs, bans, local content requirements)?
- **Sector specificity:** Are policies targeting specific {company_name} business lines?

### 4. Competitive Landscape
- **Targeted measures:** Is {company_name} specifically named, or caught in broader measures?
- **Competitor comparisons:** Are competitors facing similar patterns?
- **Strategic sectors:** Which {company_name} sectors are most politically sensitive?

### 5. Risk & Opportunity Assessment
- **Emerging risks:** Recent restrictive measures that could expand?
- **Opportunity pipeline:** Support programs {company_name} could leverage?
- **Geopolitical factors:** How do US-China tensions (or other) affect {company_name}?

## Query Strategy Note

This analysis correctly applied the **3-step query strategy** to avoid common mistakes:

âœ… **CORRECT (what we did):**
- Structured filters (policy_scope â†’ mast_chapters or intervention_types)
- Query parameter for company name only
- Avoid mixing entity names with structured parameters

âŒ **WRONG (common mistakes avoided):**
- Putting '{company_name}' in implementing_jurisdictions (wrong)
- Using intervention_types for entity names (wrong)
- Searching without structured filters (too broad)

See `gta://guide/query-syntax` for more on query strategy.

---

## Next Steps

For deeper investigation:
- **Full measure details:** `gta_get_intervention(intervention_id=X)` for any specific policy
- **Product-level impact:** `gta_get_impact_chains(intervention_id=X)` to see supply chain effects
- **Narrow scope:** Re-run with specific `policy_scope` or `implementing_countries`
- **Compare competitors:** Run same analysis for competitor companies
"""

    return [
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": prompt_text
            }
        },
        {
            "role": "user",
            "content": {
                "type": "resource",
                "resource": {
                    "uri": "gta://guide/query-syntax",
                    "mimeType": "text/markdown",
                    "text": "Query strategy and syntax guide"
                }
            }
        }
    ]
```

**Example Usage:**
```
User: "Use prompt: company-impact-tracker company_name='Tesla' policy_scope='subsidies'"

Result: Complete company analysis with:
- Correct query strategy application
- Support/restrictive/neutral categorization
- Geographic friend/foe analysis
- Timeline and trends
```

**Impact Metrics:**
- **User steps reduced:** 6 â†’ 1 (83% reduction)
- **Strategy application:** Automatic (3-step cascade)
- **Common errors prevented:** Query parameter misuse, wrong filters
- **Categorization:** Automatic (support/restrictive/neutral)

---

### Tier 2: Advanced Workflows (Implement Second)

These 5 additional prompts cover more specialized analysis patterns.

#### Prompt 6: Cross-Country Policy Comparison

**Prompt Name:** `cross-country-comparison`

**Purpose:** Compare policies across multiple countries on a specific topic, running parallel searches and aggregating results.

**Parameters:**
- `countries`: List[str] - Countries to compare (2-5 recommended)
- `policy_category`: str - 'subsidies', 'tariffs', 'export-controls', etc.
- `sector`: Optional[str] - Focus on specific sector
- `period_start`: str - Analysis start date

**Workflow Automation:**
- Runs N parallel searches (one per country)
- Aggregates statistics by country
- Creates comparison table
- Identifies outliers and patterns
- Highlights differences

**Impact:** Eliminates manual multi-query execution and comparison logic

---

#### Prompt 7: Subsidy Landscape Analysis

**Prompt Name:** `subsidy-landscape`

**Purpose:** Comprehensive subsidy analysis, correctly using MAST chapter L for broad coverage.

**Parameters:**
- `sector`: Optional[str] - Sector focus
- `implementing_countries`: Optional[List[str]] - Country filter
- `period_start`: str - Analysis start date
- `breakdown_by_type`: bool - Break down by specific subsidy types

**Workflow Automation:**
- Uses mast_chapters=['L'] correctly (not individual subsidy types)
- Groups by implementing country
- Breaks down by subsidy instrument
- Calculates totals and trends
- Compares across countries/sectors

**Impact:** Prevents common mistake of using intervention_types for subsidies

---

#### Prompt 8: Service Sector Restrictions

**Prompt Name:** `service-sector-restrictions`

**Purpose:** Analyze service sector restrictions, forcing CPC code usage (not HS).

**Parameters:**
- `service_type`: str - 'financial', 'legal', 'telecom', 'transport', etc.
- `implementing_countries`: Optional[List[str]]
- `affected_countries`: Optional[List[str]]
- `period_start`: str

**Workflow Automation:**
- Maps service_type to CPC codes (ID >= 500)
- Uses affected_sectors parameter (not affected_products)
- Groups by restriction type
- Identifies cross-border implications
- Highlights mode of supply restrictions

**Impact:** Prevents critical error of using HS codes for services (yields zero results)

---

#### Prompt 9: Export Control Timeline

**Prompt Name:** `export-control-timeline`

**Purpose:** Track export controls on specific technologies over time.

**Parameters:**
- `technology`: str - 'AI', 'semiconductors', 'quantum', 'biotech', etc.
- `implementing_countries`: List[str] - Default: ['USA', 'CHN', 'EU']
- `affected_country`: Optional[str] - Target country filter
- `include_impact_chains`: bool - Analyze affected products

**Workflow Automation:**
- Maps technology terms to intervention types (Export ban, licensing, quota)
- Applies query parameter for technology keywords
- Creates chronological timeline
- Gets impact chains for affected products
- Identifies escalation patterns

**Impact:** Handles technology terminology and export control types correctly

---

#### Prompt 10: Active Policies Dashboard

**Prompt Name:** `active-policies-dashboard`

**Purpose:** Overview of currently active (in force) policies.

**Parameters:**
- `countries`: Optional[List[str]] - Country filter
- `evaluation`: Optional[str] - Red/Amber/Green
- `policy_type`: Optional[str] - Intervention type filter
- `group_by`: str - 'country', 'type', 'sector'

**Workflow Automation:**
- Uses is_in_force=True correctly
- Sorts by date_announced descending (most recent active)
- Groups by specified dimension
- Provides statistics (count, distribution)
- Highlights recent additions

**Impact:** Uses is_in_force correctly (not date_implemented which misses many active policies)

---

## Pain Point to Prompt Mapping

### Parameter Confusion â†’ Prompts Handle It

| Pain Point | Affected Workflows | Prompts That Solve |
|-----------|-------------------|-------------------|
| **Date field confusion** (4 options) | 90% of workflows | All prompts (use date_announced by default) |
| **Query strategy cascade** (3 steps) | Company tracking, entity searches | company-impact-tracker, export-control-timeline |
| **CPC vs HS decision** | Sector analysis, service queries | sector-barriers-analysis, service-sector-restrictions |
| **MAST vs intervention_types** | Subsidy searches, broad queries | subsidy-landscape, cross-country-comparison |
| **Sorting defaults** (oldest first) | All time-sensitive queries | All prompts (apply -date_announced) |
| **Multi-tool orchestration** | Bilateral, briefing, comparison | bilateral-trade-tensions, morning-briefing |
| **is_in_force semantics** | Active policy queries | active-policies-dashboard |
| **Exclusion filter logic** | Everything-EXCEPT queries | (Could add specialized prompt) |

### Workflow Complexity â†’ Prompts Simplify

| Manual Workflow | Tool Calls | Parameters | Prompts Required | Reduction |
|----------------|-----------|-----------|-----------------|-----------|
| Recent policy analysis | 2-4 | 5 | recent-policy-analysis | 75% |
| Bilateral tensions | 3-5 | 8 | bilateral-trade-tensions | 80% |
| Morning briefing | 3-4 | 10+ | morning-briefing | 83% |
| Sector barriers | 2-4 | 7 | sector-barriers-analysis | 86% |
| Company tracking | 2-3 | 5 | company-impact-tracker | 83% |
| Cross-country comparison | 3N | 6N | cross-country-comparison | ~85% |
| Subsidy landscape | 2-3 | 5 | subsidy-landscape | 75% |
| Service restrictions | 2-3 | 6 | service-sector-restrictions | 80% |
| Export control timeline | 2-4 | 7 | export-control-timeline | 80% |
| Active policies | 1-2 | 4 | active-policies-dashboard | 75% |

**Average reduction across all workflows:** ~80% fewer user actions

---

## Implementation Roadmap

### Phase 1: Foundation (Week 1-2)
**Goal:** Implement Tier 1 prompts (5 prompts)

**Tasks:**
1. **Set up prompt infrastructure** (2 hours)
   - Add FastMCP prompt support to server
   - Create prompt helper functions
   - Set up result formatting utilities

2. **Implement Tier 1 Prompts** (12 hours total)
   - Prompt 1: recent-policy-analysis (2 hours)
   - Prompt 2: bilateral-trade-tensions (3 hours - more complex)
   - Prompt 3: morning-briefing (3 hours - multiple data sources)
   - Prompt 4: sector-barriers-analysis (2 hours)
   - Prompt 5: company-impact-tracker (2 hours)

3. **Testing** (4 hours)
   - Test each prompt with real queries
   - Verify LLM can execute workflows
   - Check result formatting
   - Validate resource embedding

4. **Documentation** (2 hours)
   - Update README with prompt examples
   - Add to USAGE_EXAMPLES.md
   - Create prompt discovery resource

**Total Phase 1 Effort:** ~20 hours

**Deliverables:**
- 5 working prompts covering 80% of use cases
- Testing suite
- User documentation
- Prompt index resource

---

### Phase 2: Advanced Prompts (Week 3-4)
**Goal:** Implement Tier 2 prompts (5 prompts)

**Tasks:**
1. **Implement Tier 2 Prompts** (10 hours)
   - Prompt 6: cross-country-comparison (2 hours)
   - Prompt 7: subsidy-landscape (2 hours)
   - Prompt 8: service-sector-restrictions (2 hours)
   - Prompt 9: export-control-timeline (2 hours)
   - Prompt 10: active-policies-dashboard (2 hours)

2. **Advanced Features** (4 hours)
   - Parallel query execution
   - Advanced aggregations
   - Timeline visualizations
   - Comparative tables

3. **Testing & Refinement** (4 hours)
   - Test complex scenarios
   - Refine prompt structures based on LLM feedback
   - Optimize result formats

**Total Phase 2 Effort:** ~18 hours

**Deliverables:**
- 5 additional prompts (10 total)
- Advanced workflow coverage
- Enhanced documentation

---

### Phase 3: Polish & Optimization (Week 5)
**Goal:** Refine user experience and measure adoption

**Tasks:**
1. **Prompt Discovery** (3 hours)
   - Create gta://prompts/index resource
   - Add "prompt suggestions" to tool responses
   - Implement prompt autocomplete/discovery

2. **User Testing** (4 hours)
   - Real user testing with prompts
   - Gather feedback on prompt usefulness
   - Identify missing workflows

3. **Optimization** (3 hours)
   - Optimize prompt performance
   - Refine result formatting based on feedback
   - Add caching where beneficial

4. **Metrics Implementation** (2 hours)
   - Track prompt usage vs direct tool usage
   - Monitor error rates
   - Measure workflow completion rates

**Total Phase 3 Effort:** ~12 hours

**Deliverables:**
- Prompt discovery system
- Usage metrics
- Optimized prompts
- User feedback incorporated

---

### Total Implementation Effort: ~50 hours (6-7 person-weeks)

---

## Success Metrics

### 1. Prompt Adoption Rate

**Metric:** % of conversations using prompts vs direct tools

**Measurement:**
```python
# Track in server.py
prompt_invocations = count_prompt_calls()
direct_tool_calls = count_tool_calls()

adoption_rate = prompt_invocations / (prompt_invocations + direct_tool_calls)
```

**Targets:**
- **Week 1-2:** 10% (initial adoption)
- **Week 3-4:** 30% (users discover prompts)
- **Month 2:** 50% (prompts become preferred)
- **Month 3+:** 60-70% (steady state)

**Success indicator:** > 50% of conversations use at least one prompt

---

### 2. Workflow Completion Rate

**Metric:** % of multi-step workflows completed successfully

**Measurement:**
- Track workflows started (e.g., bilateral analysis)
- Track workflows completed (user gets final synthesis)
- Calculate completion rate

**Targets:**
- **Without prompts (baseline):** ~40% (users abandon complex workflows)
- **With prompts:** 80%+ (guided workflows have higher completion)

**Success indicator:** 2x improvement in completion rate

---

### 3. Query Error Rate

**Metric:** % of queries with parameter errors

**Measurement:**
```python
# Track validation errors
parameter_errors = count_validation_errors()
total_queries = count_total_queries()

error_rate = parameter_errors / total_queries
```

**Common errors tracked:**
- Wrong date field usage
- CPC vs HS confusion
- Query parameter misuse
- MAST chapter mistakes
- Sorting not overridden

**Targets:**
- **Without prompts (baseline):** ~15% error rate
- **With prompts:** <5% error rate (prompts handle parameters correctly)

**Success indicator:** 3x reduction in parameter errors

---

### 4. Time to First Useful Result

**Metric:** Average time from query start to actionable insight

**Measurement:**
- Track timestamp: Query started
- Track timestamp: User receives structured results
- Calculate delta

**Targets:**
- **Without prompts (baseline):** 5-10 minutes (multiple tool calls, trial and error)
- **With prompts:** 1-2 minutes (single prompt invocation)

**Success indicator:** 5x faster time to results

---

### 5. Prompt Satisfaction Score

**Metric:** User rating of prompt usefulness

**Measurement:**
- Post-prompt survey (optional): "Was this prompt helpful? 1-5"
- Implicit: Do users re-use prompts? (repeat usage rate)

**Targets:**
- **Satisfaction rating:** > 4.0 / 5.0
- **Repeat usage rate:** > 60% (users come back to prompts)

**Success indicator:** High satisfaction + high repeat usage

---

### 6. Coverage of Use Cases

**Metric:** % of documented workflows covered by prompts

**Measurement:**
```
Workflows with prompts / Total documented workflows

Phase 1: 5/15 = 33%
Phase 2: 10/15 = 67%
Phase 3: 12/15 = 80% (with additional prompts based on feedback)
```

**Target:** > 75% coverage of common workflows

---

## Maintenance Guidelines

### When to Create New Prompts

**âœ… Create a prompt when:**
- Workflow requires 3+ tool calls
- Workflow has complex parameter decisions
- Workflow is requested frequently (>5% of queries)
- Workflow has common error patterns
- Workflow requires expert knowledge to execute correctly

**âŒ Don't create a prompt when:**
- Workflow is single tool call (direct tool use is fine)
- Workflow is rarely used (<1% of queries)
- Workflow is highly variable (prompts can't provide value)
- Existing prompt can be extended to cover use case

### Updating Existing Prompts

**When to update:**
- User feedback indicates confusion or errors
- New tool features become available
- Parameter defaults change
- Common use case patterns evolve

**Update checklist:**
- [ ] Update prompt parameters if needed
- [ ] Revise workflow steps based on feedback
- [ ] Test with real queries
- [ ] Update documentation
- [ ] Notify users of improvements (changelog)

### Prompt Quality Standards

**Every prompt should:**
1. **Handle complexity automatically:** Users provide high-level intent, prompt translates to technical parameters
2. **Embed best practices:** Apply query strategies, sorting, filtering correctly
3. **Provide guidance:** Structure LLM response with clear analysis framework
4. **Link to resources:** Embed relevant resources for context
5. **Support iteration:** Suggest next steps or follow-up actions
6. **Avoid errors:** Validate parameters, use correct defaults, prevent common mistakes

**Testing requirements:**
- Test with real user queries
- Verify LLM can execute workflow
- Check result formatting (tables, timelines, etc.)
- Validate resource embedding
- Confirm error handling

---

## Best Practices for Prompt Implementation

### 1. Parameter Design

**Good parameters:**
```python
@mcp.prompt()
async def example_prompt(
    country: str,                    # Simple, clear
    policy_type: Optional[str] = None,  # Optional with None default
    days_back: int = 30              # Sensible default
)
```

**Avoid:**
```python
@mcp.prompt()
async def bad_prompt(
    params: dict,                    # Too generic
    filter1: str = "???",            # Unclear default
    complex_nested_obj: SomeModel   # Too complex for users
)
```

### 2. Workflow Structure

**Good workflow:**
```
1. Calculate/normalize parameters (dates, codes)
2. Execute searches (parallel if possible)
3. Aggregate/process results
4. Format for embedding
5. Provide analysis framework
6. Suggest next steps
```

**Clear separation:**
- Automation (steps 1-4) in Python
- Analysis (steps 5-6) guided by LLM via prompt text

### 3. Result Formatting

**Effective formats:**
- **Tables:** For comparisons, statistics
- **Timelines:** For temporal analysis
- **Grouped lists:** For categorization
- **Summaries:** For high-level overview

**Include:**
- Total counts
- Key metrics
- Highlighted items
- Links to details (intervention IDs)

### 4. Resource Embedding

**When to embed resources:**
- Complex decision frameworks (e.g., MAST chapters guide)
- Reference data needed for analysis (e.g., intervention types)
- Syntax/strategy guides (e.g., query syntax)

**Don't embed:**
- Unrelated resources
- Large tables user won't need
- Redundant information already in prompt

### 5. Error Handling

**Graceful degradation:**
```python
try:
    results = await execute_search(params)
except APIError as e:
    return [
        UserMessage(
            content=f"Search failed: {e}\n\nTry adjusting parameters or see gta://guide/parameters"
        )
    ]
```

**Validate parameters:**
```python
if not country or len(country) != 3:
    raise ValueError("country must be 3-letter ISO code (e.g., 'USA', 'CHN')")
```

---

## Conclusion

### Current State: Layer 3 Absent

The GTA MCP server has **zero prompts** despite excellent Layer 1 (Tools) and Layer 2 (Resources) implementation. Users must manually navigate 15+ complex workflows.

### Opportunity: High-Value Gap

Documentation reveals sophisticated workflows requiring:
- 3-5 tool calls per workflow
- 4-5 parameter decisions per query
- Expert knowledge of classification systems, date fields, query strategies

### Recommendation: Implement 10 Strategic Prompts

**Tier 1 (Critical - Implement First):**
1. recent-policy-analysis - Date handling, sorting
2. bilateral-trade-tensions - Dual searches, timeline alignment
3. morning-briefing - Daily monitoring, multiple data sources
4. sector-barriers-analysis - CPC vs HS, sector mapping
5. company-impact-tracker - Query strategy, categorization

**Tier 2 (Advanced - Implement Second):**
6. cross-country-comparison - Parallel searches, aggregation
7. subsidy-landscape - MAST taxonomy, breakdown
8. service-sector-restrictions - CPC codes, cross-border analysis
9. export-control-timeline - Technology terms, escalation patterns
10. active-policies-dashboard - is_in_force, grouping

### Expected Impact

**User Experience:**
- 80% reduction in workflow complexity (7 steps â†’ 1 prompt)
- 3x reduction in query errors
- 5x faster time to results
- 2x improvement in workflow completion rate

**Coverage:**
- Phase 1: 33% of workflows (5 prompts)
- Phase 2: 67% of workflows (10 prompts)
- Covers 80%+ of common use cases

**Implementation Effort:**
- Phase 1: 20 hours (Tier 1 prompts)
- Phase 2: 18 hours (Tier 2 prompts)
- Phase 3: 12 hours (polish)
- **Total: ~50 hours (6-7 person-weeks)**

### Priority: High

Layer 3 implementation is the **single largest opportunity** to improve user experience. The absence of guided workflows forces users to navigate complex parameter decisions and multi-step processes that could be automated.

**Next Steps:**
1. Approve implementation roadmap
2. Begin Phase 1 with Tier 1 prompts
3. Test with real users
4. Measure adoption and iterate

---

**Document Version:** 1.0
**Next Review:** After Phase 1 implementation (Tier 1 prompts)
**Feedback:** Update based on real-world usage patterns and user feedback
